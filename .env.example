# MemoryLLM Configuration
# Copy this file to .env and fill in your specific values

# Cognee CLI Configuration
# Path to your Cognee CLI installation directory
COGNEE_CLI_PATH="/Users/talimoreno/cognee"

# URL of the actual LLM provider (e.g., OpenRouter, Azure, etc.)
# Should include the full path like: https://api.openrouter.ai/v1
LLM_PROVIDER_URL="https://api.openrouter.ai/v1"

# Optional: Cognee environment variables
# These will be passed to the Cognee CLI process
# ENABLE_BACKEND_ACCESS_CONTROL=false

# Terms that trigger skipping memory search (comma-separated)
# Useful for UI-generated internal messages like title generation
SKIP_SEARCH_TERMS="Here are the first few user messages, Generate a title"

# Rate limiting: maximum number of messages per second to the LLM (default 1)
MAX_MESSAGES_PER_SECOND=1